{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Connect With Me in Linkedin** :- https://www.linkedin.com/in/dheerajkumar1997/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Methods: Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-1: Import Dependencies and Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76020, 371)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Dataset\n",
    "data = pd.read_csv('./dataset/Santander-Customer-Satisfaction-data/train.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53214, 370), (22806, 370))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(labels=['TARGET'], axis=1),data['TARGET'],test_size=0.3,random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep a Copy of the Original training and test data for later use\n",
    "X_train_original = X_train.copy()\n",
    "X_test_original = X_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-2: Get and Remove Constant Features from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Constant Features\n",
    "# remove constant features\n",
    "constant_features = [feat for feat in X_train.columns if X_train[feat].std() == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53214, 332), (22806, 332))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.drop(labels=constant_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=constant_features, axis=1, inplace=True)\n",
    " \n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-3: Remove Quasi-Constant Features from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove quasi-constant features\n",
    "sel = VarianceThreshold(threshold=0.01)  # 0.1 indicates 99% of observations approximately\n",
    "sel.fit(X_train)  # fit finds the features with low variance\n",
    "sum(sel.get_support()) # how many not quasi-constant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the remaining features\n",
    "features_to_keep = X_train.columns[sel.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53214, 268), (22806, 268))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the constant features\n",
    "X_train = sel.transform(X_train)\n",
    "X_test = sel.transform(X_test)\n",
    " \n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the arrays back to Dataframes\n",
    "X_train= pd.DataFrame(X_train)\n",
    "X_train.columns = features_to_keep\n",
    " \n",
    "X_test= pd.DataFrame(X_test)\n",
    "X_test.columns = features_to_keep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-4: Detect and Remove Duplicate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicated features in the training set\n",
    "duplicated_feat = []\n",
    "for i in range(0, len(X_train.columns)):\n",
    "    if i % 10 == 0:  # this helps me understand how the loop is going\n",
    "        print(i)\n",
    " \n",
    "    col_1 = X_train.columns[i]\n",
    " \n",
    "    for col_2 in X_train.columns[i + 1:]:\n",
    "        if X_train[col_1].equals(X_train[col_2]):\n",
    "            duplicated_feat.append(col_2)\n",
    "            \n",
    "len(duplicated_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53214, 252), (22806, 252))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicated features\n",
    "X_train.drop(labels=duplicated_feat, axis=1, inplace=True)\n",
    "X_test.drop(labels=duplicated_feat, axis=1, inplace=True)\n",
    " \n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep a copy of the dataset except constant and duplicated variables to measure the performance of machine learning models\n",
    "X_train_basic_filter = X_train.copy()\n",
    "X_test_basic_filter = X_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-5: Detect and Remove Features with Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlated features:  133\n"
     ]
    }
   ],
   "source": [
    "# Find and remove correlated features\n",
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr\n",
    " \n",
    "corr_features = correlation(X_train, 0.8)\n",
    "print('correlated features: ', len(set(corr_features)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53214, 119), (22806, 119))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.drop(labels=corr_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=corr_features, axis=1, inplace=True)\n",
    " \n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-6: Performance of Final Dataset on Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build Random Forest Classifier and compare performance in train and test set\n",
    "def run_randomForests(X_train, X_test, y_train, y_test):\n",
    "    rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
    "    rf.fit(X_train, y_train)\n",
    "    print('Train set')\n",
    "    pred = rf.predict_proba(X_train)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    print('Test set')\n",
    "    pred = rf.predict_proba(X_test)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.8012315676132568\n",
      "Test set\n",
      "Random Forests roc-auc: 0.7900499757912425\n"
     ]
    }
   ],
   "source": [
    "# Performance of RFC on Original Dataset with Constants, Duplicates and Correlated Features\n",
    "run_randomForests(X_train_original.drop(labels=['ID'], axis=1),\n",
    "                  X_test_original.drop(labels=['ID'], axis=1),\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.8016570464386661\n",
      "Test set\n",
      "Random Forests roc-auc: 0.7910330692426437\n"
     ]
    }
   ],
   "source": [
    "# Performance of RFC on Dataset without any Constants or Duplicates\n",
    "run_randomForests(X_train_basic_filter.drop(labels=['ID'], axis=1),\n",
    "                  X_test_basic_filter.drop(labels=['ID'], axis=1),\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.8073914001626228\n",
      "Test set\n",
      "Random Forests roc-auc: 0.793766724733034\n"
     ]
    }
   ],
   "source": [
    "# Performance of RFC on Dataset without any Correlated Features\n",
    "run_randomForests(X_train.drop(labels=['ID'], axis=1),\n",
    "                  X_test.drop(labels=['ID'], axis=1),\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that removing constant, quasi-constant, duplicated and correlated features reduced the feature space dramatically (from 371 to 119), without affecting the performance of the random forests (0.790 vs 0.794). If anything else, the model can now make even better predictions. And this is most likely due to the fact that high feature spaces affect negatively the performance of random forests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build logistic regression and compare performance in train and test set\n",
    "def run_logistic(X_train, X_test, y_train, y_test):\n",
    "    # function to train and test the performance of logistic regression\n",
    "    logit = LogisticRegression(random_state=44)\n",
    "    logit.fit(X_train, y_train)\n",
    "    print('Train set')\n",
    "    pred = logit.predict_proba(X_train)\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    print('Test set')\n",
    "    pred = logit.predict_proba(X_test)\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic Regression roc-auc: 0.8070006916699176\n",
      "Test set\n",
      "Logistic Regression roc-auc: 0.7936258651482251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hare krishna\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\base.py:340: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    }
   ],
   "source": [
    "# Performance of Logistic Regression Classifier on Original Dataset\n",
    "scaler = StandardScaler().fit(X_train_original.drop(labels=['ID'], axis=1))\n",
    " \n",
    "run_logistic(scaler.transform(X_train_original.drop(labels=['ID'], axis=1)),\n",
    "             scaler.transform(X_test_original.drop(labels=['ID'], axis=1)),\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic Regression roc-auc: 0.8063203720892692\n",
      "Test set\n",
      "Logistic Regression roc-auc: 0.7932285496615372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hare krishna\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\base.py:340: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    }
   ],
   "source": [
    "# Performance of Logistic Regression Classifier on Dataset without Constants, Quasi-Constants and Duplicates\n",
    "scaler = StandardScaler().fit(X_train_basic_filter.drop(labels=['ID'], axis=1))\n",
    " \n",
    "run_logistic(scaler.transform(X_train_basic_filter.drop(labels=['ID'], axis=1)),\n",
    "             scaler.transform(X_test_basic_filter.drop(labels=['ID'], axis=1)),\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic Regression roc-auc: 0.7964875051006453\n",
      "Test set\n",
      "Logistic Regression roc-auc: 0.7929020262989868\n"
     ]
    }
   ],
   "source": [
    "# Performance of Logistic Regression Classifier on Dataset without Correaltion between Features\n",
    "scaler = StandardScaler().fit(X_train.drop(labels=['ID'], axis=1))\n",
    " \n",
    "run_logistic(scaler.transform(X_train.drop(labels=['ID'], axis=1)),\n",
    "             scaler.transform(X_test.drop(labels=['ID'], axis=1)),\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Connect With Me in Linkedin** :- https://www.linkedin.com/in/dheerajkumar1997/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
